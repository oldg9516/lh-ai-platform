# –ê–Ω–∞–ª–∏–∑: –ù–æ–≤—ã–µ —Ñ–∞–∑—ã –ø—Ä–æ–µ–∫—Ç–∞ –∏ Agno Learning Machine

## –ö–æ–Ω—Ç–µ–∫—Å—Ç

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–ø—Ä–æ—Å–∏–ª –∞–Ω–∞–ª–∏–∑:
1. –ò–∑—É—á–∏—Ç—å –Ω–æ–≤—ã–µ —Ñ–∞–∑—ã –ø—Ä–æ–µ–∫—Ç–∞ (Phase 6-10) –∏–∑ PROGRESS.md –∏ docs/08-COPILOTKIT-GENERATIVE-UI.md
2. –û—Ü–µ–Ω–∏—Ç—å –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å Agno Learning Machine –¥–ª—è —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è support –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–≤–µ—á–∞—é—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã –∫–ª–∏–µ–Ω—Ç–æ–≤

**Current status:** Phase 5 complete (AgentOS Analytics Service operational)

---

## –û–±–∑–æ—Ä –Ω–æ–≤—ã—Ö —Ñ–∞–∑ (Phase 6-10)

### Phase 6: Generative UI + HITL (8 –Ω–µ–¥–µ–ª—å)

**–¶–µ–ª—å:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Human-in-the-Loop –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–ª—è write-–æ–ø–µ—Ä–∞—Ü–∏–π —á–µ—Ä–µ–∑ CopilotKit framework

**–ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

1. **CopilotKit + AG-UI –ø—Ä–æ—Ç–æ–∫–æ–ª** (–æ—Ç–∫—Ä—ã—Ç—ã–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Google/AWS/Microsoft)
   - Controlled Generative UI: —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–∑–¥–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, –∞–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç –∫–∞–∫–æ–π –ø–æ–∫–∞–∑–∞—Ç—å
   - Streaming: Python backend ‚Üí React frontend (HTTP SSE –∏–ª–∏ WebSocket)
   - Type-safe: TypeScript + Pydantic

2. **HITL —Ñ–æ—Ä–º—ã –¥–ª—è write-–æ–ø–µ—Ä–∞—Ü–∏–π:**
   - `PauseSubscriptionForm` ‚Äî –≤—ã–±–æ—Ä –º–µ—Å—è—Ü–µ–≤ –ø–∞—É–∑—ã
   - `ChangeAddressForm` ‚Äî —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–¥—Ä–µ—Å–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π (Google Maps API)
   - `DamageClaimForm` ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ + photo upload (S3/MinIO)
   - `SkipMonthForm` ‚Äî –≤—ã–±–æ—Ä –º–µ—Å—è—Ü–∞ –ø—Ä–æ–ø—É—Å–∫–∞
   - `FrequencyChangeForm` ‚Äî monthly/bi-monthly/quarterly

3. **Informational widgets (no confirmation):**
   - `TrackingCard` ‚Äî tracking number, carrier, –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä, –∫–∞—Ä—Ç–∞
   - `OrderHistoryTable` ‚Äî –∏—Å—Ç–æ—Ä–∏—è –∑–∞–∫–∞–∑–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
   - `BoxContentsCard` ‚Äî —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∫–æ—Ä–æ–±–∫–µ
   - `PaymentHistoryCard` ‚Äî timeline –ø–ª–∞—Ç–µ–∂–µ–π

4. **Backend AG-UI endpoint:**
   ```python
   @router.post("/api/copilot")
   async def copilot_stream(request):
       async for chunk in agent.arun_stream(message):
           if chunk.type == "tool_call":
               # –û—Ç–ø—Ä–∞–≤–∏—Ç—å frontendToolCall event ‚Üí React —Ñ–æ—Ä–º–∞
               confirmation = await wait_for_confirmation()
               if confirmation.approved:
                   result = await execute_real_tool()
   ```

5. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è:**
   - Chatwoot widget embedding (iframe)
   - Tool updates: `@tool(requires_confirmation=True)` –≤ Agno SDK
   - Audit logging: `tool_executions` —Å `confirmation_timestamp`, `user_approved`
   - –†–µ–∞–ª—å–Ω—ã–µ API: Zoho CRM, Pay API, shipping providers

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –Ω–∏ –æ–¥–Ω–∞ write-–æ–ø–µ—Ä–∞—Ü–∏—è –±–µ–∑ —è–≤–Ω–æ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
- ‚úÖ UX: –Ω–∞—Ç–∏–≤–Ω—ã–µ UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫
- ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–µ –î–û –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞ backend
- ‚úÖ Type-safe, reusable, testable
- ‚úÖ –°—Ç–∞–Ω–¥–∞—Ä—Ç AG-UI (–Ω–µ vendor lock-in)

---

### Phase 7: Architecture Refactoring (4 –Ω–µ–¥–µ–ª–∏)

**–¶–µ–ª—å:** –£–ª—É—á—à–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

1. **Context Builder** (`agents/context_builder.py`)
   - Customer profile injection (name, join_date, LTV)
   - Active subscription (frequency, next_charge)
   - Recent orders summary (last 3)
   - Smart history truncation (—Å—Ç–∞—Ä—ã–µ ‚Üí summarize)
   - Outstanding context injection

2. **Sentiment tracking –≤ Router**
   - –î–æ–±–∞–≤–∏—Ç—å `sentiment` field: positive/neutral/negative/frustrated
   - –î–æ–±–∞–≤–∏—Ç—å `escalation_signal` field (customer wants human)
   - Enhanced escalation context: structured handoff note, smart assignee routing

3. **Pinecone reranking**
   - Initial search: top_k=20 (hybrid)
   - Reranking: bge-reranker-v2-m3, top_n=5
   - Metadata filtering: product, language, freshness

4. **Orchestrator Pattern** (`agents/orchestrator.py`)
   - –í—ã–Ω–µ—Å—Ç–∏ –≤—Å—é –ª–æ–≥–∏–∫—É –∏–∑ monolith `api/routes.py`
   - Clean separation: router ‚Üí context ‚Üí agent ‚Üí eval ‚Üí assembly ‚Üí persistence
   - Parallel execution: agent + outstanding detection (asyncio.gather)

5. **Model Optimization**
   - Router: GPT-5.1 ‚Üí GPT-5-mini (90% ‚¨áÔ∏è cost)
   - Eval Gate: GPT-5.1 ‚Üí Claude Sonnet 4.5 (better judgment)
   - Support (retention): GPT-5.1 ‚Üí Sonnet 4.5 + reasoning (50% ‚¨ÜÔ∏è quality)
   - Benchmarking –Ω–∞ golden dataset –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏

---

### Phase 8: Multi-Agent Teams (5 –Ω–µ–¥–µ–ª—å)

**–¶–µ–ª—å:** –ü–µ—Ä–µ–π—Ç–∏ –æ—Ç single-agent factory –∫ multi-agent teams —Å —É–∑–∫–æ–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π

**Team Architecture:**

1. **Intake Agent** (GPT-5-mini)
   - Triage + routing decision
   - Sentiment analysis
   - Initial classification

2. **Specialist Agents:**
   - **Billing Specialist** ‚Äî payment, refund, subscription questions
   - **Shipping Specialist** ‚Äî delivery, tracking, address
   - **Retention Specialist** ‚Äî pause, cancel, downsell (Sonnet 4.5 + reasoning)
   - **Quality Specialist** ‚Äî damage, leaking, replacement

3. **QA Agent** (Claude Sonnet 4.5)
   - –ó–∞–º–µ–Ω—è–µ—Ç Eval Gate
   - Better judgment –¥–ª—è tone/accuracy/safety
   - Retry logic: QA reject ‚Üí specialist refines ‚Üí QA re-check

4. **Integration:**
   - Agno Team orchestration
   - Inter-agent communication (shared context)
   - A/B testing: single-agent vs team (10% traffic)
   - Langfuse comparison: resolution rate, latency, quality scores

---

### Phase 9: AI Ops & Continuous Learning (Ongoing)

**–¶–µ–ª—å:** –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥, feedback loop, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

1. **AI Ops Dashboard** (`services/analytics/ai_ops.py`)
   - `get_failure_patterns()` ‚Äî —Ç–æ–ø –ø—Ä–∏—á–∏–Ω—ã draft/escalate
   - `get_knowledge_gaps()` ‚Äî –≤–æ–ø—Ä–æ—Å—ã —Å –Ω–∏–∑–∫–æ–π accuracy
   - `get_tone_drift()` ‚Äî tracking —Ç–æ–Ω–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
   - `suggest_prompt_updates()` ‚Äî ML-based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

2. **–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:**
   - AI Resolution Rate (target >70%)
   - Eval Gate Pass Rate (target >80%)
   - Escalation Rate (target <10%)
   - Average Confidence (target >0.8)
   - Category Accuracy (per category, >0.75)
   - Response Time p95 (<10s)

3. **Feedback Loop** (`learning/feedback.py`)
   - `collect_human_edit()` ‚Äî –∫–æ–≥–¥–∞ human —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç AI –æ—Ç–≤–µ—Ç
   - `classify_edit()` ‚Äî tone, accuracy, safety, completeness
   - `is_recurring_pattern()` ‚Äî –¥–µ—Ç–µ–∫—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫
   - `generate_prompt_update()` ‚Äî –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—é –ø—Ä–æ–º–ø—Ç–æ–≤

4. **Agno Learning Machine** (—Å–º. –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∏–∂–µ)
   ```python
   learning = LearningMachine(db=get_postgres_db(), scope="support_tools")
   agent = Agent(..., learning=learning, learn_from_errors=True)
   ```

5. **Continuous Evaluation**
   - Daily auto-eval –Ω–∞ golden dataset (338 items)
   - Compare —Å baseline scores
   - Alert –µ—Å–ª–∏ regression >5%

---

### Phase 10: Scale + Production (6 –Ω–µ–¥–µ–ª—å)

**–¶–µ–ª—å:** Full production deployment —Å gradual rollout

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

1. **Auto-Send Expansion**
   - Per-category confidence thresholds (retention ‚Üí 0.9, gratitude ‚Üí 0.7)
   - Gradual rollout: 10% ‚Üí 25% ‚Üí 50% ‚Üí 100%

2. **Production Monitoring**
   - Langfuse 100% tracing
   - Agno Control Plane integration (os.agno.com)
   - Real-time performance dashboard
   - Cost tracking (per category/model/day)

3. **CRM Integration ‚Äî Proactive Support**
   - Detect subscription issues BEFORE customer contacts
   - Automated outreach (Chatwoot proactive message)
   - Predictive churn prevention (ML model: predict cancel ‚Üí offer downsell)

4. **n8n Migration (Gradual)**
   - Phase 10.1: 10% email ‚Üí AI platform (A/B test)
   - Phase 10.2: 50% email ‚Üí AI platform
   - Phase 10.3: 100% email ‚Üí AI platform
   - Fallback: –µ—Å–ª–∏ AI fails ‚Üí n8n backup pipeline

5. **Feedback Loop v2 (Autonomous)**
   - Production traces ‚Üí Langfuse eval ‚Üí –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ (no human in loop)
   - Auto-detect quality regression
   - Auto-rollback –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤

---

## üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ö–æ–¥–∫–∏: Agno Learning Machine

### –ß—Ç–æ —ç—Ç–æ –ù–ï –¥–µ–ª–∞–µ—Ç (–≤–æ–ø—Ä–µ–∫–∏ –æ–∂–∏–¥–∞–Ω–∏—è–º –∏–∑ PROGRESS.md)

**Learning Machine –ù–ï –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—à–∏–±–æ–∫.**

–ò–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è Agno SDK –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:

‚ùå **–ù–ï —É—á–∏—Ç—Å—è –∏–∑:**
- Tool execution errors (–Ω–µ—Ç `learn_from_errors` flag –∏–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
- Human corrections –≤ Chatwoot (–Ω–µ—Ç HITL integration —Å edits)
- Eval results –∏–∑ Langfuse (–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è observability/tracing, –Ω–µ training)
- User feedback (–Ω–µ—Ç —Å–∏—Å—Ç–µ–º—ã —Å–±–æ—Ä–∞ feedback –∏–ª–∏ quality scoring)
- Response quality issues (–Ω–µ—Ç eval‚Üílearning feedback loop)

### –ß—Ç–æ Learning Machine –†–ï–ê–õ–¨–ù–û –¥–µ–ª–∞–µ—Ç

‚úÖ **Learning Machine = User Personalization & Memory**, –Ω–µ Self-Improvement

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**

1. **User Profile** ‚Äî structured user data
   ```python
   {
       "name": "Sarah Cohen",
       "timezone": "Asia/Jerusalem",
       "company": "Lev Haolam",
       "role": "subscriber",
       "subscription_tier": "premium"
   }
   ```

2. **User Memory** ‚Äî remember customer preferences
   ```python
   UserMemoryConfig(
       max_memories=10,  # Last 10 significant preferences
       memory_types=["preference", "communication_style", "ongoing_projects"]
   )
   ```

3. **Learned Knowledge** ‚Äî collective insights shared across all users
   - Global knowledge base (–Ω–µ per-user)
   - Accumulates facts discovered during conversations
   - Shared context –¥–ª—è –≤—Å–µ—Ö —Å–µ—Å—Å–∏–π

4. **Session Context** ‚Äî conversation-specific planning and state
   - –¢–µ–∫—É—â–∏–π conversation plan
   - Intermediate results
   - Context –¥–ª—è multi-turn

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è Support Platform

```python
from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.learn import LearningMachine, UserMemoryConfig

# PostgreSQL backend –¥–ª—è Learning Machine
db = PostgresDb(
    db_url=settings.supabase_url,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é Supabase DB
    schema="learning",  # –û—Ç–¥–µ–ª—å–Ω–∞—è —Å—Ö–µ–º–∞ –¥–ª—è learning tables
)

# Learning config
learning = LearningMachine(
    user_profile=True,  # Enable customer profile storage
    user_memory=UserMemoryConfig(
        max_memories=10,  # –ü–æ–º–Ω–∏—Ç—å 10 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö preferences
        memory_types=["preference", "communication_style", "issues"]
    ),
)

# Support Agent —Å learning
agent = Agent(
    name="support_shipping",
    model=OpenAIChat(id="gpt-5.1"),
    tools=[track_package, get_subscription],
    db=db,
    learning=learning,
    user_id=customer_email,  # –ö–†–ò–¢–ò–ß–ù–û: user_id –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
    instructions=[...],
)
```

**Database tables (auto-created):**
- `learning.agent_profile` ‚Äî user profiles
- `learning.agent_memory` ‚Äî user memories
- `learning.agent_knowledge` ‚Äî learned knowledge
- `learning.agent_sessions` ‚Äî session context

### Use Cases –¥–ª—è Lev Haolam

‚úÖ **–•–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:**

1. **Customer Preferences Across Sessions**
   ```
   Session 1: "–Ø –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é –æ–±—â–∞—Ç—å—Å—è –∫—Ä–∞—Ç–∫–æ, –±–µ–∑ –¥–µ—Ç–∞–ª–µ–π"
   ‚Üí –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ user_memory: communication_style="concise"

   Session 2 (—á–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é): Agent –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—Ä–∞—Ç–∫–∏–π —Å—Ç–∏–ª—å
   ```

2. **Recurring Issues Tracking**
   ```
   Session 1: "–ü–æ—Å—ã–ª–∫–∞ –æ–ø–æ–∑–¥–∞–ª–∞ –≤ –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑"
   ‚Üí –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ user_memory: past_issue="delayed_delivery"

   Session 2: Agent –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç tracking –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç customer
   ```

3. **Product Preferences**
   ```
   Session 1: "–Ø –Ω–µ –ø—å—é –∞–ª–∫–æ–≥–æ–ª—å, —Ç–æ–ª—å–∫–æ –±–µ–∑–∞–ª–∫–æ–≥–æ–ª—å–Ω—ã–µ –≤–∏–Ω–∞"
   ‚Üí –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ user_profile: product_preference="alcohol_free"

   Session 2: Customization request ‚Üí Agent –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç alcohol-free –æ–ø—Ü–∏–∏
   ```

4. **Communication Style**
   ```
   Session 1: Customer –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Hebrew
   ‚Üí –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ user_profile: preferred_language="he"

   Session 2: Agent –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ Hebrew (–µ—Å–ª–∏ multi-language support)
   ```

‚ùå **–ù–ï –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:**
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ tone –Ω–∞ –æ—Å–Ω–æ–≤–µ human corrections
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è tool parameters –Ω–∞ –æ—Å–Ω–æ–≤–µ failures
- Learning from eval gate rejections
- Prompt refinement –Ω–∞ –æ—Å–Ω–æ–≤–µ low-accuracy patterns

---

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: –ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Self-Learning –¥–ª—è Support –ê–≥–µ–Ω—Ç–æ–≤

–î–ª—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –Ω—É–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å **custom pipelines**. Agno Learning Machine –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏, –Ω–æ –æ—Å–Ω–æ–≤–Ω–æ–π self-learning –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å custom.

### –°—Ç—Ä–∞—Ç–µ–≥–∏—è: Dual-Track Approach

**Track 1: Agno Learning Machine (–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è)**
- Customer preferences across sessions
- Communication style memory
- Product preferences
- Past issues tracking

**Track 2: Custom Learning Pipelines (quality improvement)**
- Eval-driven learning
- Correction learning from human edits
- Tool analytics and optimization
- Few-shot enhancement

---

### 1. Eval-Driven Learning Pipeline

**–¶–µ–ª—å:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ª—É—á—à–∞—Ç—å –ø—Ä–æ–º–ø—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ eval results

```python
# learning/eval_driven.py
async def analyze_eval_failures(category: str, days: int = 7):
    """Analyze eval failures for a category to find patterns."""

    # 1. Get failed evals
    failures = await db.query("""
        SELECT er.eval_decision, er.eval_reasoning,
               cs.primary_category, cm.customer_message, cm.agent_response
        FROM eval_results er
        JOIN chat_sessions cs ON er.session_id = cs.session_id
        JOIN chat_messages cm ON cs.session_id = cm.session_id
        WHERE cs.primary_category = %s
          AND er.eval_decision IN ('draft', 'escalate')
          AND er.created_at >= NOW() - INTERVAL '%s days'
        ORDER BY er.created_at DESC
        LIMIT 50
    """, (category, days))

    # 2. Use GPT to extract patterns
    pattern_prompt = f"""
    Analyze these {len(failures)} eval failures for {category} category.

    For each failure, identify:
    1. Root cause (tone, accuracy, safety, completeness)
    2. Common mistake pattern
    3. How to fix it

    Failures:
    {json.dumps([{
        "message": f.customer_message,
        "response": f.agent_response,
        "reason": f.eval_reasoning
    } for f in failures], indent=2)}

    Output as JSON:
    {{
        "patterns": [
            {{"issue": "too formal tone", "frequency": 15, "fix": "use warmer language"}},
            ...
        ],
        "suggested_instruction_updates": ["instruction text", ...]
    }}
    """

    analysis = await openai_client.chat.completions.create(
        model="gpt-5.1",
        messages=[{"role": "user", "content": pattern_prompt}],
        response_format={"type": "json_object"}
    )

    patterns = json.loads(analysis.choices[0].message.content)

    # 3. If pattern repeats 3+ times, suggest instruction update
    for pattern in patterns["patterns"]:
        if pattern["frequency"] >= 3:
            await create_instruction_update_suggestion(
                category=category,
                issue=pattern["issue"],
                fix=pattern["fix"],
                suggested_instructions=patterns["suggested_instruction_updates"]
            )

    return patterns

# Weekly cron job
async def weekly_instruction_refinement():
    """Run eval-driven learning for all categories."""
    for category in CATEGORY_CONFIG.keys():
        patterns = await analyze_eval_failures(category, days=7)

        # If regression detected, alert
        if len(patterns["patterns"]) > 5:
            await send_alert(f"Category {category} has {len(patterns['patterns'])} recurring issues")
```

---

### 2. Correction Learning Pipeline

**–¶–µ–ª—å:** Learn from human edits –≤ Chatwoot

```python
# learning/correction_learning.py
from chatwoot.client import ChatwootClient

async def capture_human_correction(conversation_id: int):
    """Capture when human agent edits AI response in Chatwoot."""

    # 1. Get conversation messages
    messages = await chatwoot_client.get_messages(conversation_id)

    # Find AI message + human edit
    ai_message = None
    human_edit = None

    for i, msg in enumerate(messages):
        if msg["sender_type"] == "bot" and msg["private"] == False:
            ai_message = msg
            # Check if next message is human edit (private note)
            if i + 1 < len(messages) and messages[i+1]["sender_type"] == "user" and messages[i+1]["private"]:
                human_edit = messages[i+1]
                break

    if not ai_message or not human_edit:
        return None

    # 2. Classify the correction type
    correction_analysis = await openai_client.chat.completions.create(
        model="gpt-5-mini",
        messages=[{
            "role": "user",
            "content": f"""
            Analyze this human correction of AI response.

            AI Response: {ai_message["content"]}
            Human Edit: {human_edit["content"]}

            Classify the correction type:
            - tone (too formal, too casual, wrong emotion)
            - accuracy (wrong information, missing details)
            - safety (subscription confirmation, refund policy)
            - completeness (missing steps, incomplete answer)

            Output JSON:
            {{
                "type": "tone|accuracy|safety|completeness",
                "specific_issue": "description",
                "key_changes": ["change 1", "change 2"]
            }}
            """
        }],
        response_format={"type": "json_object"}
    )

    correction = json.loads(correction_analysis.choices[0].message.content)

    # 3. Store in correction_patterns table
    await db.execute("""
        INSERT INTO correction_patterns
        (conversation_id, category, ai_response, human_edit, correction_type, specific_issue, key_changes, created_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, NOW())
    """, (
        conversation_id,
        ai_message.get("category"),
        ai_message["content"],
        human_edit["content"],
        correction["type"],
        correction["specific_issue"],
        json.dumps(correction["key_changes"])
    ))

    # 4. Check for recurring patterns
    recurring = await db.query("""
        SELECT correction_type, specific_issue, COUNT(*) as frequency
        FROM correction_patterns
        WHERE category = %s AND created_at >= NOW() - INTERVAL '7 days'
        GROUP BY correction_type, specific_issue
        HAVING COUNT(*) >= 3
        ORDER BY frequency DESC
    """, (ai_message.get("category"),))

    # 5. If pattern repeats 3+ times, create alert
    for pattern in recurring:
        await send_alert(f"Recurring {pattern['correction_type']} issue in {ai_message.get('category')}: {pattern['specific_issue']} ({pattern['frequency']} times)")

# Chatwoot webhook integration
@router.post("/api/webhook/chatwoot/correction")
async def chatwoot_correction_webhook(payload: dict):
    """Triggered when human agent creates private note after AI response."""

    if payload["event"] == "message_created" and payload["message_type"] == "incoming" and payload["private"]:
        # This might be a correction
        await capture_human_correction(payload["conversation"]["id"])
```

---

### 3. Few-Shot Learning Enhancement

**–¶–µ–ª—å:** Use top corrections as few-shot examples

```python
# agents/support.py (update create_support_agent)
async def create_support_agent(category: str, email: str = None) -> Agent:
    """Create support agent with few-shot learning from corrections."""

    # Get top 5 corrections for this category (best human edits)
    corrections = await db.query("""
        SELECT ai_response, human_edit, specific_issue
        FROM correction_patterns
        WHERE category = %s
          AND correction_type IN ('tone', 'accuracy')
        ORDER BY created_at DESC
        LIMIT 5
    """, (category,))

    # Build few-shot examples
    few_shot_messages = []
    for corr in corrections:
        few_shot_messages.extend([
            {
                "role": "assistant",
                "content": corr.ai_response,
                "metadata": {"issue": corr.specific_issue}
            },
            {
                "role": "user",
                "content": f"[Correction needed: {corr.specific_issue}]. Better response: {corr.human_edit}"
            }
        ])

    # Create agent with few-shot learning + personalization
    agent = Agent(
        name=f"support_{category}",
        model=_resolve_model(category),
        tools=_resolve_tools(category),
        knowledge=_get_knowledge(category),
        instructions=_load_instructions(category),
        additional_input=few_shot_messages,  # Inject corrections as few-shot examples
        user_id=email,
        # Agno Learning Machine –¥–ª—è customer personalization
        learning=LearningMachine(
            user_profile=True,
            user_memory=UserMemoryConfig(max_memories=10)
        ) if email else None,
    )

    return agent
```

---

### 4. Tool Analytics Dashboard

**–¶–µ–ª—å:** Optimize tool parameters –Ω–∞ –æ—Å–Ω–æ–≤–µ execution patterns

```python
# services/analytics/tool_analytics.py
async def analyze_tool_usage(tool_name: str, days: int = 30):
    """Analyze tool execution patterns to find parameter issues."""

    executions = await db.query("""
        SELECT tool_name, tool_args, tool_result,
               success, error_message, execution_time_ms
        FROM tool_executions
        WHERE tool_name = %s
          AND created_at >= NOW() - INTERVAL '%s days'
        ORDER BY created_at DESC
    """, (tool_name, days))

    analysis = {
        "total_executions": len(executions),
        "success_rate": sum(1 for e in executions if e.success) / len(executions),
        "avg_execution_time": sum(e.execution_time_ms for e in executions) / len(executions),
        "common_errors": {},
        "parameter_patterns": {}
    }

    # Analyze errors
    for exec in executions:
        if not exec.success and exec.error_message:
            error_key = exec.error_message[:100]  # First 100 chars
            analysis["common_errors"][error_key] = analysis["common_errors"].get(error_key, 0) + 1

    # Top 5 errors
    analysis["top_errors"] = sorted(
        analysis["common_errors"].items(),
        key=lambda x: x[1],
        reverse=True
    )[:5]

    # Parameter analysis
    for exec in executions:
        args = json.loads(exec.tool_args) if isinstance(exec.tool_args, str) else exec.tool_args
        for param, value in args.items():
            if param not in analysis["parameter_patterns"]:
                analysis["parameter_patterns"][param] = {"values": {}, "errors": {}}

            value_str = str(value)
            analysis["parameter_patterns"][param]["values"][value_str] = \
                analysis["parameter_patterns"][param]["values"].get(value_str, 0) + 1

            if not exec.success:
                analysis["parameter_patterns"][param]["errors"][value_str] = \
                    analysis["parameter_patterns"][param]["errors"].get(value_str, 0) + 1

    # Generate recommendations
    recommendations = []
    for param, data in analysis["parameter_patterns"].items():
        # Find values with high error rate
        for value, count in data["errors"].items():
            error_rate = count / data["values"].get(value, 1)
            if error_rate > 0.5 and count >= 3:
                recommendations.append(f"Parameter '{param}' with value '{value}' has {error_rate*100:.0f}% error rate. Consider adding validation or updating instructions.")

    analysis["recommendations"] = recommendations
    return analysis
```

---

## –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è Phase 9 (AI Ops & Learning)

**1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Agno Learning Machine –î–õ–Ø:**
- ‚úÖ Customer personalization (preferences, communication style)
- ‚úÖ User memory across sessions (recurring issues, product preferences)
- ‚úÖ Profile storage (language, timezone, subscription_tier)

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
# –î–æ–±–∞–≤–∏—Ç—å –≤ create_support_agent()
learning = LearningMachine(
    user_profile=True,
    user_memory=UserMemoryConfig(max_memories=10)
) if customer_email else None

agent = Agent(..., learning=learning, user_id=customer_email)
```

**–≠—Ñ—Ñ–µ–∫—Ç:** 10-15% —É–ª—É—á—à–µ–Ω–∏–µ customer experience (personalized responses)

---

**2. –ü–æ—Å—Ç—Ä–æ–∏—Ç—å Custom Pipelines –î–õ–Ø:**
- ‚úÖ Eval-driven learning (eval failures ‚Üí instruction updates)
- ‚úÖ Correction learning (Chatwoot edits ‚Üí few-shot examples)
- ‚úÖ Tool analytics (execution patterns ‚Üí parameter guidance)
- ‚úÖ Response quality improvement (eval results ‚Üí prompt refinement)

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã:**
1. **Week 1-2:** Correction Learning Pipeline (highest ROI)
   - Chatwoot webhook –¥–ª—è human edits
   - `correction_patterns` table
   - Alert —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è recurring issues

2. **Week 3:** Few-Shot Enhancement
   - Inject top 5 corrections –≤ agent context
   - A/B test: few-shot vs baseline

3. **Week 4:** Eval-Driven Learning
   - Weekly analysis –Ω–∞ eval failures
   - Automatic instruction update suggestions

4. **Week 5:** Tool Analytics Dashboard
   - Parameter error analysis
   - Recommendations –¥–ª—è tool guidance

**Expected Impact:**
- 15-20% reduction –≤ eval failures (from corrections)
- 10-15% improvement –≤ tone consistency (from few-shot)
- 5-10% reduction –≤ tool errors (from analytics)
- Better customer experience (from personalization)

---

**3. Database Schema –¥–ª—è Custom Learning:**

```sql
-- Correction patterns table
CREATE TABLE correction_patterns (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id INTEGER,
    category TEXT,
    ai_response TEXT,
    human_edit TEXT,
    correction_type TEXT, -- tone, accuracy, safety, completeness
    specific_issue TEXT,
    key_changes JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_correction_category_date
ON correction_patterns(category, created_at DESC);

-- Instruction update suggestions
CREATE TABLE instruction_updates (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    category TEXT,
    current_version INTEGER,
    suggested_version INTEGER,
    issue_pattern TEXT,
    suggested_fix TEXT,
    supporting_examples JSONB, -- Array of correction IDs
    status TEXT, -- pending, approved, rejected, deployed
    created_at TIMESTAMPTZ DEFAULT NOW(),
    deployed_at TIMESTAMPTZ
);

-- Learning analytics
CREATE TABLE learning_analytics (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    metric_type TEXT, -- eval_failure_rate, correction_frequency, tool_error_rate
    category TEXT,
    metric_value FLOAT,
    details JSONB,
    analyzed_at TIMESTAMPTZ DEFAULT NOW()
);
```

---

## –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å: –ü—Ä–∏–º–µ–Ω–∏–º–æ –ª–∏ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ Agno Dash –¥–ª—è support –∞–≥–µ–Ω—Ç–æ–≤?

**–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: –ß–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–∏–º–µ–Ω–∏–º–æ, –Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏.**

### ‚úÖ –ß–¢–û –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:

**Agno Learning Machine** –æ—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:
- **Customer personalization** ‚Äî –ø–æ–º–Ω–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏
- **Communication style adaptation** ‚Äî –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞
- **Product preferences** ‚Äî –ø–æ–º–Ω–∏—Ç—å product choices
- **Issue history** ‚Äî track recurring problems per customer

**–≠—Ñ—Ñ–µ–∫—Ç:** –£–ª—É—á—à–µ–Ω–∏–µ customer experience –Ω–∞ 10-15% –∑–∞ —Å—á–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏

### ‚ùå –ß–¢–û –ù–ï —Ä–∞–±–æ—Ç–∞–µ—Ç:

**Agno Learning Machine –ù–ï –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è:**
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤
- Learning from eval failures –∏–ª–∏ human corrections
- Tool parameter optimization
- Prompt refinement –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫

**–ü—Ä–∏—á–∏–Ω–∞:** Learning Machine –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è user memory, –Ω–µ –¥–ª—è agent self-improvement

### ‚úÖ –†–ï–®–ï–ù–ò–ï: –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥

**Dual-Track Strategy:**

1. **Track 1: Agno Learning Machine** (–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è)
   - –î–æ–±–∞–≤–∏—Ç—å –≤ create_support_agent()
   - –•—Ä–∞–Ω–∏—Ç—å customer preferences –≤ learning.agent_memory
   - –†–∞–±–æ—Ç–∞–µ—Ç out-of-the-box, –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞

2. **Track 2: Custom Learning Pipelines** (–∫–∞—á–µ—Å—Ç–≤–æ)
   - Eval-driven learning (weekly analysis ‚Üí instruction updates)
   - Correction learning (Chatwoot edits ‚Üí few-shot examples)
   - Tool analytics (execution patterns ‚Üí guidance)
   - Few-shot enhancement (inject corrections)

**–ò—Ç–æ–≥–æ:**
- Learning Machine (–ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è): 1-2 –¥–Ω—è integration
- Custom pipelines (–∫–∞—á–µ—Å—Ç–≤–æ): 2-3 –Ω–µ–¥–µ–ª–∏ development
- **Total effort: 3-4 weeks**
- **Expected improvement: 25-35% (combined effect)**

---

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

### Immediate (Phase 5 complete ‚úÖ)
- Analytics service operational
- Knowledge base loaded
- All endpoints tested

### Next (Phase 6 start)
- Setup CopilotKit React app
- Implement AG-UI streaming endpoint
- Create first HITL form (PauseSubscriptionForm)

### Parallel track (Learning foundation)
- Add Agno Learning Machine –¥–ª—è customer personalization
- Build correction_patterns table
- Implement Chatwoot webhook –¥–ª—è correction capture
- Start collecting data –¥–ª—è eval-driven learning
